{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e14b49a",
   "metadata": {},
   "source": [
    "# Exercise KNN\n",
    "Fill the ellipses `...` with code, and don't remove `assert` lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a07c6",
   "metadata": {},
   "source": [
    "## We will use the Titanic dataset.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "| VARIABLE  | DESCRIPTIONS | \n",
    "|---|---|\n",
    "| **Survived** | Survival (0 = No, 1 = Yes) |\n",
    "| **Pclass** | Ticket class\t(1 = 1st, 2 = 2nd, 3 = 3rd) |\n",
    "| **Name** | Name of Passenger |\n",
    "| **Sex** | sex |\n",
    "| **Age** | Age in years |\n",
    "| **Sibsp** | # of siblings / spouses aboard the Titanic\t |\n",
    "| **Parch** | # of parents / children aboard the Titanic |\n",
    "| **Ticket** | Ticket number |\n",
    "| **Fare** | Passenger fare |\n",
    "| **Cabin** | Cabin number |\n",
    "| **Embarked** | Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton) |\n",
    "\n",
    "### Variable Notes\n",
    "**Pclass**: A proxy for socio-economic status (SES)\n",
    "\n",
    "- 1st = Upper\n",
    "\n",
    "- 2nd = Middle\n",
    "\n",
    "- 3rd = Lower\n",
    "\n",
    "**Age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**Sibsp**: The dataset defines family relations in this way...\n",
    "\n",
    "- Sibling = brother, sister, stepbrother, stepsister\n",
    "\n",
    "- Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**Parch**: The dataset defines family relations in this way...\n",
    "\n",
    "- Parent = mother, father\n",
    "\n",
    "- Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "- Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Survived'])\n",
    "Y = data['Survived']\n",
    "\n",
    "# split our data into training and testing set with 90:10 ratio\n",
    "# use a fixed random state for reproducible results\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5c2ac",
   "metadata": {},
   "source": [
    "### Data Preprocess\n",
    "We will preprocess the data !!! Remember the training and test set separately to avoid data snooping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove category features\n",
    "for i in x_train:\n",
    "    if(x_train[i].dtypes == object):\n",
    "        x_train = x_train.drop(columns=i)\n",
    "        x_test = x_test.drop(columns=i)\n",
    "        \n",
    "# Fill na values with 0\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x_train, x_test, y_train, y_test to numpy array\n",
    "import numpy as np\n",
    "x_train_np = x_train.to_numpy()\n",
    "x_test_np = x_test.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Scale the training and test set with sklearn libary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_np)\n",
    "x_train_np = scaler.transform(x_train_np)\n",
    "x_test_np = scaler.transform(x_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242da4da",
   "metadata": {},
   "source": [
    "### KNN: $k$-Nearest Neighbors\n",
    "Evaluate the test set with data from the training set.\n",
    "\n",
    "In case of ties, pick the smallest class (i.e. we prefer class 0 to class 1 to class 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f06c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, no training is needed for KNN!\n",
    "def evaluateKNN_single(k, x_train, y_train, data):\n",
    "    '''\n",
    "    Evaluate the classification for `data` with k-nearest neighbor\n",
    "    given training set (x_train, y_train).\n",
    "\n",
    "    Note that this function takes in one input instead of the whole\n",
    "    testing set.\n",
    "    \n",
    "    Input:\n",
    "        k      : hyperparameter for KNN\n",
    "        x_train: features of training set\n",
    "        y_train: labels of training set\n",
    "        data   : features of the data point to be evaluated\n",
    "    Output:\n",
    "        Classification of the input data point.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f4b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code for the whole dataset\n",
    "def evaluateKNN(k, x_train=x_train_np, y_train=y_train_np, x_test=x_test_np, y_test=y_test_np):    \n",
    "    correct = sum(list(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test))))\n",
    "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert evaluateKNN_single(10, x_train_np, y_train_np, x_test_np[0]) in [0, 1], \"The return value is not of the correct type\"\n",
    "evaluateKNN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ba1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert evaluateKNN_single(10, x_train_np, y_train_np, x_test_np[0]) in [0, 1], \"The return value is not of the correct type\"\n",
    "evaluateKNN(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306430e2",
   "metadata": {},
   "source": [
    "### (Optional) Try other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef139511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
